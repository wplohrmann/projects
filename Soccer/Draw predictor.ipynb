{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f9 = r'/home/william/Dropbox/Kaggle/Soccer/season9.csv'\n",
    "f10 = r'/home/william/Dropbox/Kaggle/Soccer/season10.csv'\n",
    "f11 = r'/home/william/Dropbox/Kaggle/Soccer/season11.csv'\n",
    "f12 = r'/home/william/Dropbox/Kaggle/Soccer/season12.csv'\n",
    "f13 = r'/home/william/Dropbox/Kaggle/Soccer/season13.csv'\n",
    "f14 = r'/home/william/Dropbox/Kaggle/Soccer/season14.csv'\n",
    "f15 = r'/home/william/Dropbox/Kaggle/Soccer/season15.csv'\n",
    "f16 = r'/home/william/Dropbox/Kaggle/Soccer/season16.csv'\n",
    "\n",
    "\n",
    "df9 = pd.read_csv(f9)\n",
    "df10 = pd.read_csv(f10)\n",
    "df11 = pd.read_csv(f11)\n",
    "df12 = pd.read_csv(f12)\n",
    "df13 = pd.read_csv(f13)\n",
    "df14 = pd.read_csv(f14)\n",
    "df15 = pd.read_csv(f15)\n",
    "df16 = pd.read_csv(f16)\n",
    "\n",
    "df_train = df9.append([df10,df11,df12,df13,df14,df15],ignore_index=True)\n",
    "\n",
    "train_X = df_train.drop('Home/Away win',axis=1)\n",
    "train_y = df_train['Home/Away win']\n",
    "train_y = (train_y==0)+0\n",
    "\n",
    "test_X = df16.drop('Home/Away win',axis=1)\n",
    "test_y = df16['Home/Away win']\n",
    "test_y = (test_y==0)+0\n",
    "\n",
    "\n",
    "\n",
    "#Adding a feature to indicate extra likelihood of draw\n",
    "draw_NB = GaussianNB()\n",
    "draw_NB.fit(train_X,train_y)\n",
    "\n",
    "predicted_p = draw_NB.predict_proba(train_X)[:,1]\n",
    "indices = predicted_p.argsort()\n",
    "indices = indices[-np.sum(train_y):]\n",
    "train_X['draw_maybe'] = 0\n",
    "train_X.iloc[indices,-1] = 1 \n",
    "\n",
    "predicted_p = draw_NB.predict_proba(test_X)[:,1]\n",
    "indices = predicted_p.argsort()\n",
    "no_draw = int(np.average(train_y)*test_y.size)\n",
    "indices = indices[-no_draw:]\n",
    "test_X['draw_maybe'] = 0\n",
    "test_X.iloc[indices,-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.742105263158\n",
      "0.778947368421\n"
     ]
    }
   ],
   "source": [
    "print(1-np.average(train_y))\n",
    "print(1-np.average(test_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69999999999999996"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GNB = GaussianNB()\n",
    "GNB.fit(train_X,train_y)\n",
    "GNB.score(test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RFC\n",
    "RFC = RandomForestClassifier()\n",
    "RFC.fit(train_X,train_y)\n",
    "RFC.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
