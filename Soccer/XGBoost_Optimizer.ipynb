{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "import graphviz\n",
    "\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Ideas:\n",
    "#Use a custom objective function (XGBoost) to maximize profits directly \n",
    "#i.e. not caring about the accuracy of the predictions\n",
    "\n",
    "#Change odds from H D A to sum H/D H/A\n",
    "#Try it you will like it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Project steps:\n",
    "#1\n",
    "#Extract relevant features from football-data.co.uk. Do some feature engineering.\n",
    "#Expect some improvement from competence_difference. Better formula may help\n",
    "#Do we need more data?\n",
    "\n",
    "#2\n",
    "#Predict outcomes of each match. Training using data since 2009. Leave 2015 and 2016.\n",
    "#2015 is for cross-validation of classifiers. 2016 is for testing \n",
    "\n",
    "#3\n",
    "#Estimate probability that prediction is correct. In other words, how confident are we?\n",
    "\n",
    "#4 \n",
    "#Using all the information gathered, formulate a betting strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f9 = r'/home/william/Dropbox/Kaggle/Soccer/season9.csv'\n",
    "f10 = r'/home/william/Dropbox/Kaggle/Soccer/season10.csv'\n",
    "f11 = r'/home/william/Dropbox/Kaggle/Soccer/season11.csv'\n",
    "f12 = r'/home/william/Dropbox/Kaggle/Soccer/season12.csv'\n",
    "f13 = r'/home/william/Dropbox/Kaggle/Soccer/season13.csv'\n",
    "f14 = r'/home/william/Dropbox/Kaggle/Soccer/season14.csv'\n",
    "f15 = r'/home/william/Dropbox/Kaggle/Soccer/season15.csv'\n",
    "f16 = r'/home/william/Dropbox/Kaggle/Soccer/season16.csv'\n",
    "\n",
    "\n",
    "df9 = pd.read_csv(f9)\n",
    "df10 = pd.read_csv(f10)\n",
    "df11 = pd.read_csv(f11)\n",
    "df12 = pd.read_csv(f12)\n",
    "df13 = pd.read_csv(f13)\n",
    "df14 = pd.read_csv(f14)\n",
    "df15 = pd.read_csv(f15)\n",
    "df16 = pd.read_csv(f16)\n",
    "\n",
    "#df16['sum_odds'] = df16['B365H']+df16['B365A']+df16['B365D']\n",
    "#df16['H'] = df16['B365H']/df16['B365D']\n",
    "#df16['A'] = df16['B365A']/df16['B365D']\n",
    "#df16 = df16.drop(['B365H', 'B365D', 'B365A'],axis=1)\n",
    "\n",
    "\n",
    "df_test = df16\n",
    "\n",
    "df_train = df9.append([df10,df11,df12,df13,df14,df15],ignore_index=True)\n",
    "#df_train['sum_odds'] = df_train['B365H']+df_train['B365A']+df_train['B365D']\n",
    "#df_train['H'] = df_train['B365H']/df_train['B365D']\n",
    "#df_train['A'] = df_train['B365A']/df_train['B365D']\n",
    "#df_train = df_train.drop(['B365H', 'B365D', 'B365A'],axis=1)\n",
    "\n",
    "f_training = r'/home/william/Dropbox/Kaggle/Soccer/training.csv'\n",
    "f_testing = r'/home/william/Dropbox/Kaggle/Soccer/testing.csv'\n",
    "\n",
    "#df_train = pd.read_csv(f_training)\n",
    "#df_test = pd.read_csv(f_testing)\n",
    "\n",
    "#df_train = df_train.drop('B365A',axis=1)\n",
    "#df_test = df_test.drop('B365A',axis=1)\n",
    "\n",
    "\n",
    "train_X = df_train.drop('Home/Away win',axis=1)\n",
    "train_y = df_train['Home/Away win']+1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_X = df_test.drop('Home/Away win',axis=1)\n",
    "test_y = df_test['Home/Away win']+1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60263157894736841"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = XGBClassifier()\n",
    "clf.fit(train_X,train_y)\n",
    "clf.score(test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train_X,label=train_y)\n",
    "dtest = xgb.DMatrix(test_X,label=test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {''}\n",
    "clf = xgb.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60789473684210527"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average((first.predict(dtest)==test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print ('start running example to used customized objective function')\n",
    "\n",
    "dtrain = xgb.DMatrix('../data/agaricus.txt.train')\n",
    "dtest = xgb.DMatrix('../data/agaricus.txt.test')\n",
    "\n",
    "# note: for customized objective function, we leave objective as default\n",
    "# note: what we are getting is margin value in prediction\n",
    "# you must know what you are doing\n",
    "param = {'max_depth': 2, 'eta': 1, 'silent': 1}\n",
    "watchlist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "num_round = 2\n",
    "\n",
    "# user define objective function, given prediction, return gradient and second order gradient\n",
    "# this is log likelihood loss\n",
    "def logregobj(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    preds = 1.0 / (1.0 + np.exp(-preds))\n",
    "    grad = preds - labels\n",
    "    hess = preds * (1.0-preds)\n",
    "    return grad, hess\n",
    "\n",
    "# user defined evaluation function, return a pair metric_name, result\n",
    "# NOTE: when you do customized loss function, the default prediction value is margin\n",
    "# this may make builtin evaluation metric not function properly\n",
    "# for example, we are doing logistic loss, the prediction is score before logistic transformation\n",
    "# the builtin evaluation error assumes input is after logistic transformation\n",
    "# Take this in mind when you use the customization, and maybe you need write customized evaluation function\n",
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    # return a pair metric_name, result\n",
    "    # since preds are margin(before logistic transformation, cutoff at 0)\n",
    "    return 'error', float(sum(labels != (preds > 0.0))) / len(labels)\n",
    "\n",
    "# training with customized objective, we can also do step by step training\n",
    "# simply look at xgboost.py's implementation of train\n",
    "bst = xgb.train(param, dtrain, num_round, watchlist, logregobj, evalerror)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
