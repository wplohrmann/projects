{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Ideas:\n",
    "#Use a custom objective function (XGBoost) to maximize profits directly \n",
    "#i.e. not caring about the accuracy of the predictions\n",
    "\n",
    "#Change odds from H D A to sum H/D H/A\n",
    "#Try it you will like it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Project steps:\n",
    "#1\n",
    "#Extract relevant features from football-data.co.uk. Do some feature engineering.\n",
    "#Expect some improvement from competence_difference. Better formula may help\n",
    "#Do we need more data?\n",
    "\n",
    "#2\n",
    "#Predict outcomes of each match. Training using data since 2009. Leave 2015 and 2016.\n",
    "#2015 is for cross-validation of classifiers. 2016 is for testing \n",
    "\n",
    "#3\n",
    "#Estimate probability that prediction is correct. In other words, how confident are we?\n",
    "\n",
    "#4 \n",
    "#Using all the information gathered, formulate a betting strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f9 = r'/home/william/Dropbox/Kaggle/Soccer/season9.csv'\n",
    "f10 = r'/home/william/Dropbox/Kaggle/Soccer/season10.csv'\n",
    "f11 = r'/home/william/Dropbox/Kaggle/Soccer/season11.csv'\n",
    "f12 = r'/home/william/Dropbox/Kaggle/Soccer/season12.csv'\n",
    "f13 = r'/home/william/Dropbox/Kaggle/Soccer/season13.csv'\n",
    "f14 = r'/home/william/Dropbox/Kaggle/Soccer/season14.csv'\n",
    "f15 = r'/home/william/Dropbox/Kaggle/Soccer/season15.csv'\n",
    "f16 = r'/home/william/Dropbox/Kaggle/Soccer/season16.csv'\n",
    "\n",
    "\n",
    "df9 = pd.read_csv(f9)\n",
    "df10 = pd.read_csv(f10)\n",
    "df11 = pd.read_csv(f11)\n",
    "df12 = pd.read_csv(f12)\n",
    "df13 = pd.read_csv(f13)\n",
    "df14 = pd.read_csv(f14)\n",
    "df15 = pd.read_csv(f15)\n",
    "df16 = pd.read_csv(f16)\n",
    "df_test = df16\n",
    "\n",
    "df_train = df9.append([df10,df11,df12,df13,df14,df15],ignore_index=True)\n",
    "#df_train['sum_odds'] = df_train['B365H']+df_train['B365A']+df_train['B365D']\n",
    "#df_train['H'] = df_train['B365H']/df_train['B365D']\n",
    "#df_train['A'] = df_train['B365A']/df_train['B365D']\n",
    "#df_train = df_train.drop(['B365H', 'B365D', 'B365A'],axis=1)\n",
    "\n",
    "f_training = r'/home/william/Dropbox/Kaggle/Soccer/training.csv'\n",
    "f_testing = r'/home/william/Dropbox/Kaggle/Soccer/testing.csv'\n",
    "\n",
    "#df_train = pd.read_csv(f_training)\n",
    "#df_test = pd.read_csv(f_testing)\n",
    "\n",
    "#df_train = df_train.drop('B365A',axis=1)\n",
    "#df_test = df_test.drop('B365A',axis=1)\n",
    "\n",
    "\n",
    "train_X = df_train.drop('Home/Away win',axis=1)\n",
    "train_y = df_train['Home/Away win']\n",
    "\n",
    "\n",
    "#df16['sum_odds'] = df16['B365H']+df16['B365A']+df16['B365D']\n",
    "#df16['H'] = df16['B365H']/df16['B365D']\n",
    "#df16['A'] = df16['B365A']/df16['B365D']\n",
    "#df16 = df16.drop(['B365H', 'B365D', 'B365A'],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "test_X = df_test.drop('Home/Away win',axis=1)\n",
    "test_y = df_test['Home/Away win']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#Adding a feature to indicate extra likelihood of draw\n",
    "train_draw = np.array((train_y==0)+0)\n",
    "test_draw = np.array((test_y==0)+0)\n",
    "draw_logit = GaussianNB()\n",
    "draw_logit.fit(train_X,train_draw)\n",
    "\n",
    "predicted_p = draw_logit.predict_proba(train_X)[:,1]\n",
    "indices = predicted_p.argsort()\n",
    "indices = indices[-np.sum(train_draw):]\n",
    "train_X['draw_maybe'] = 0\n",
    "train_X.iloc[indices,-1] = 1 \n",
    "\n",
    "predicted_p = draw_logit.predict_proba(test_X)[:,1]\n",
    "indices = predicted_p.argsort()\n",
    "no_draw = int(np.average(train_draw)*test_draw.size)\n",
    "indices = indices[-no_draw:]\n",
    "test_X['draw_maybe'] = 0\n",
    "test_X.iloc[indices,-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_f1_score(y_true,y_pred):\n",
    "    t_away = np.sum(y_true==-1)\n",
    "    t_draw = np.sum(y_true==0)\n",
    "    t_home = np.sum(y_true==1)\n",
    "    \n",
    "    p_away = np.sum(y_true==-1)\n",
    "    p_draw = np.sum(y_true==0)\n",
    "    p_home = np.sum(y_true==1)\n",
    "    \n",
    "    total = y_true.size\n",
    "    \n",
    "    return (p_away/t_away)*(p_draw/t_draw)*(p_home/t_home)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.610526315789\n"
     ]
    }
   ],
   "source": [
    "#SVC\n",
    "train_X['B365H'] = np.log(train_X['B365H']-1)\n",
    "train_X['B365D'] = np.log(train_X['B365D']-1)\n",
    "\n",
    "test_X['B365H'] = np.log(test_X['B365H'])\n",
    "test_X['B365D'] = np.log(test_X['B365D'])\n",
    "\n",
    "train_X = scale(train_X)\n",
    "test_X = scale(test_X)\n",
    "\n",
    "parameter_candidates = [{'C':[10,100,1000], \n",
    "                         'gamma': [0.0001,0.001,0.01]}]\n",
    "\n",
    "\n",
    "clf = GridSearchCV(SVC(probability=True),parameter_candidates,scoring=make_scorer(new_f1_score),n_jobs=-1)\n",
    "clf = GridSearchCV(SVC(probability=True),parameter_candidates,n_jobs=-1)\n",
    "\n",
    "clf.fit(train_X,train_y)\n",
    "svc = clf.best_estimator_\n",
    "svc.fit(train_X,train_y)\n",
    "print(svc.score(test_X,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 61,   0,  48],\n",
       "       [ 12,   0,  72],\n",
       "       [ 16,   0, 171]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y,svc.predict(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  0.610526315789\n",
      "After:  0.597368421053\n"
     ]
    }
   ],
   "source": [
    "#Predicting draws: The ULTIMATE CHALLENGE (okay)\n",
    "train_draw = np.array((train_y==0)+0)\n",
    "test_draw = np.array((test_y==0)+0)\n",
    "draw_logit = GaussianNB()\n",
    "draw_logit.fit(train_X,train_draw)\n",
    "multiplier = 1\n",
    "p_draw = test_draw.size*(1-multiplier*np.average(train_draw))\n",
    "\n",
    "predicted_p = draw_logit.predict_proba(test_X)[:,1]\n",
    "indices = predicted_p.argsort()\n",
    "indices = indices[int(p_draw):]\n",
    "prediction = voter.predict(test_X)\n",
    "print('Before: ', np.average(prediction==test_y))\n",
    "prediction[indices] = 0\n",
    "print('After: ', np.average(prediction==test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "voter = svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set-up for betting\n",
    "odds = np.array(df16.iloc[:,1:4])\n",
    "results = np.array(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profit:  0.131868421053\n",
      "Bets used:  1.0\n"
     ]
    }
   ],
   "source": [
    "#Betting strategy 1: Only bet if you're sure of winning (p)\n",
    "p = voter.predict_proba(test_X)\n",
    "pick = voter.predict(test_X)\n",
    "\n",
    "#Replace home/away with draws from above\n",
    "pick[indices] = 0\n",
    "\n",
    "picked_odds = odds[np.arange(380),-pick+1]\n",
    "profits = np.where(pick==results,picked_odds-1,-1)\n",
    "\n",
    "threshold = 0\n",
    "bets = (np.max(p,axis=1)-threshold)\n",
    "bets[np.max(p,axis=1)<threshold] = 0\n",
    "bets[bets!=0] = 1\n",
    "\n",
    "profits = profits*bets\n",
    "profit = np.sum(profits)/np.sum(bets)\n",
    "\n",
    "print('Profit: ', profit)\n",
    "print('Bets used: ', len(bets[bets!=0])/380)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profit:  0.129217687075\n",
      "Bets used:  0.7736842105263158\n"
     ]
    }
   ],
   "source": [
    "#Betting strategy 2: Only bet when it's worth it (p*odds) (p from logit)\n",
    "\n",
    "new_train_y = (train_y==voter.predict(train_X))*1\n",
    "\n",
    "logit2 = LogisticRegressionCV(n_jobs=-1)\n",
    "logit2.fit(train_X,new_train_y)\n",
    "\n",
    "\n",
    "p = logit2.predict_proba(test_X)[:,1]\n",
    "\n",
    "\n",
    "pick = voter.predict(test_X)\n",
    "pick[indices] = 0\n",
    "\n",
    "picked_odds = odds[np.arange(pick.size),-pick+1]\n",
    "profits = np.where(pick==results,picked_odds-1,-1)\n",
    "\n",
    "threshold = 0.5\n",
    "expected = p*picked_odds-(1-p)\n",
    "bets = np.where(expected>threshold,1.,0)\n",
    "#bets *= np.abs(expected-threshold)\n",
    "\n",
    "profits = profits*bets\n",
    "profit = np.sum(profits)/np.sum(bets)\n",
    "\n",
    "print('Profit: ', profit)\n",
    "print('Bets used: ', len(bets[bets!=0])/380)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profit:  -0.264455782313\n",
      "Bets used:  0.7736842105263158\n"
     ]
    }
   ],
   "source": [
    "#Betting strategy 3: Bet on the most profitable (using logit) outcome but only if over a threshold\n",
    "#lol this is stupid\n",
    "p = logit.predict_proba(test_X)\n",
    "pick = np.argmax(p*odds-(1-p),axis=1)\n",
    "expected = (p*odds-(1-p))[np.arange(results.size),pick]\n",
    "picked_odds = odds[np.arange(results.size),pick]\n",
    "\n",
    "threshold = 0.9\n",
    "bets = np.where(expected>threshold,1,0)\n",
    "\n",
    "profits = np.where(results==-pick+1,picked_odds-1,-1)\n",
    "\n",
    "profit = np.sum(profits)/np.sum(bets)\n",
    "\n",
    "print('Profit: ', profit)\n",
    "print('Bets used: ', len(bets[bets!=0])/380)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profit:  0.0656052631579\n",
      "Bets used:  1\n"
     ]
    }
   ],
   "source": [
    "#Betting strategy 4: Always bet home (yes he did the absolute legend)\n",
    "profits = np.where(results==1,odds[:,0]-1,-1)\n",
    "profit = np.sum(profits)/len(test_X)\n",
    "\n",
    "print('Profit: ', profit)\n",
    "print('Bets used: ', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profit:  0.127512437811\n",
      "Bets used:  0.5289473684210526\n"
     ]
    }
   ],
   "source": [
    "#Betting strategy 5: Only bet when it's worth it (using the confusion matrix)\n",
    "\n",
    "pick = voter.predict(test_X)\n",
    "picked_odds = odds[np.arange(pick.size),-pick+1]\n",
    "profits = np.where(pick==results,picked_odds-1,-1)\n",
    "\n",
    "cross_pick = np.array(cross_val_predict(voter,train_X,train_y))\n",
    "actual_results = np.array(train_y)\n",
    "\n",
    "mtrx = confusion_matrix(actual_results,cross_pick)\n",
    "p = np.copy(pick).astype('float')\n",
    "p[pick==-1] = mtrx[0,0]/np.sum(mtrx[0,:])\n",
    "p[pick==1] = mtrx[2,2]/np.sum(mtrx[2,:])\n",
    "p[pick==0] = mtrx[1,1]/np.sum(mtrx[1,:])\n",
    "\n",
    "threshold = 1\n",
    "expected = p*picked_odds-(1-p)\n",
    "bets = np.where(expected>threshold,1.,0)\n",
    "#bets *= np.abs(expected-threshold)\n",
    "\n",
    "profits = profits*bets\n",
    "profit = np.sum(profits)/np.sum(bets)\n",
    "\n",
    "print('Profit: ', profit)\n",
    "print('Bets used: ', len(bets[bets!=0])/380)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  -0.0820757894737\n",
      "Standard Deviation:  0.0765888405872\n"
     ]
    }
   ],
   "source": [
    "#Betting strategy 6: Bet randomly\n",
    "M = 100\n",
    "profit_ns = np.zeros(M)\n",
    "for n in np.arange(M):\n",
    "    pick = np.random.randint(-1,2,results.size)\n",
    "    picked_odds = odds[np.arange(pick.size),-pick+1]\n",
    "    profits = np.where(pick==results,picked_odds-1,-1)\n",
    "    profit = np.sum(profits)/pick.size\n",
    "    profit_ns[n] = profit\n",
    "print('Mean: ', np.average(profit_ns))\n",
    "print('Standard Deviation: ', np.std(profit_ns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  0,  1, -1,  0,  0,  1,  0,  0,  1,  1,  0,  0, -1,  0,  0,\n",
       "       -1, -1,  0,  0, -1,  1, -1,  0,  1,  1,  0,  0,  1,  1, -1,  1,  0,\n",
       "        1,  0, -1,  0,  1,  1,  0,  0,  1, -1, -1,  1,  0, -1,  0,  1,  1,\n",
       "        0,  0,  0,  1,  0,  1, -1, -1,  1,  1, -1, -1,  1,  1,  1, -1,  0,\n",
       "        0,  1,  0,  0,  1,  1,  1, -1,  0,  1,  0,  0, -1,  0, -1,  0,  0,\n",
       "       -1,  0,  0,  0,  1, -1, -1, -1,  1, -1,  1,  1, -1,  1,  1, -1,  0,\n",
       "        0,  1, -1, -1, -1, -1,  1,  1, -1,  0,  1,  0, -1, -1,  0, -1, -1,\n",
       "        1, -1,  0,  0, -1,  0,  1,  1,  1,  1,  0,  1,  1,  1,  1,  1, -1,\n",
       "        1,  1, -1,  1, -1,  1,  1,  1, -1,  1,  0,  0, -1,  1, -1,  0, -1,\n",
       "        1,  0,  0, -1, -1,  1,  0,  1,  1, -1,  0,  0,  1,  1, -1,  0,  0,\n",
       "       -1, -1, -1,  1,  0,  0, -1,  1, -1, -1, -1,  1, -1,  0,  1, -1, -1,\n",
       "       -1,  0, -1,  0,  1, -1, -1,  0,  0,  0,  1,  0,  1, -1,  0,  1,  1,\n",
       "        0,  0,  0,  1, -1, -1, -1,  0,  0,  0, -1,  1,  1, -1,  1, -1,  1,\n",
       "        0,  1, -1, -1, -1,  1,  0,  1,  0,  0,  1, -1,  1,  0,  1,  1,  1,\n",
       "        1,  0,  0,  0,  1,  1,  1,  1,  1,  0,  1,  1,  1, -1,  1,  0,  0,\n",
       "       -1,  0, -1,  1,  1,  1, -1,  0, -1,  1,  1,  1,  0, -1, -1,  1, -1,\n",
       "        1, -1, -1, -1,  0,  0,  1,  0,  0,  0, -1,  1, -1,  1,  1,  0, -1,\n",
       "        0,  0,  0, -1,  0,  1, -1,  0,  0,  1, -1,  1, -1, -1,  1, -1,  0,\n",
       "        0,  0, -1,  1,  0,  0,  1,  0,  1,  0, -1,  1,  1,  0,  0, -1,  1,\n",
       "        0,  1, -1,  0,  1,  1,  0,  0, -1, -1,  0,  1,  0, -1,  0, -1,  0,\n",
       "        1,  1, -1,  1,  0, -1,  0,  0, -1,  0,  1,  1,  0,  0,  1,  0, -1,\n",
       "        1,  0,  0, -1,  0, -1,  1, -1, -1, -1,  0, -1,  1, -1, -1, -1,  0,\n",
       "       -1,  0,  0, -1,  1,  0])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected sequence or array-like, got <class 'int'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-5e9e6784b289>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmtrx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpick\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \"\"\"\n\u001b[0;32m--> 240\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \"\"\"\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \"\"\"\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \"\"\"\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             raise TypeError(\"Expected sequence or array-like, got %s\" %\n\u001b[0;32m--> 122\u001b[0;31m                             type(x))\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected sequence or array-like, got <class 'int'>"
     ]
    }
   ],
   "source": [
    "mtrx = confusion_matrix(results,pick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = ['Away', 'Draw', 'Home']\n",
    "sns.heatmap(mtrx,annot=True,xticklabels=labels,yticklabels=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Replace 0 with 0 mtrx[0,0]/np.sum(mtrx[0,:])\n",
    "ps = np.random.rand(len(test_y))\n",
    "mtrx[0,0]/np.sum(mtrx[0,:])\n",
    "initial_pred = voter.predict(test_X)+1\n",
    "final_pred = np.zeros(initial_pred.shape)\n",
    "proportion = 1\n",
    "\n",
    "\n",
    "\n",
    "for n in np.arange(3):\n",
    "    every = np.arange(initial_pred.size)\n",
    "    ind1 = np.where(initial_pred==n) #Initial prediction is n\n",
    "    ind2 = np.where(ps<=mtrx[n,0]/np.sum([mtrx[n,:]])) #Probability is less than the first threshold\n",
    "    ind3 = np.where(ps<=(mtrx[n,0]+mtrx[n,1])/np.sum([mtrx[n,:]])) #Probability is less than the second threshold\n",
    "    ind4 = np.where(ps>(mtrx[n,0]+mtrx[n,1])/np.sum([mtrx[n,:]])) #Probability is less than the second threshold\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    final_pred[np.intersect1d(ind1,ind3)] = 1\n",
    "    final_pred[np.intersect1d(ind1,ind2)] = 0\n",
    "    final_pred[np.intersect1d(ind1,ind4)] = 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 57,   0,  52],\n",
       "       [ 27,   0,  57],\n",
       "       [ 45,   0, 142]])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y+1,final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52368421052631575"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(final_pred==test_y+1)/380"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage</th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>B365A</th>\n",
       "      <th>competence_difference</th>\n",
       "      <th>draw_maybe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.67</td>\n",
       "      <td>3.60</td>\n",
       "      <td>5.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2.63</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.70</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2.63</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1.91</td>\n",
       "      <td>3.30</td>\n",
       "      <td>4.33</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1.17</td>\n",
       "      <td>6.50</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1.20</td>\n",
       "      <td>6.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>1.73</td>\n",
       "      <td>3.60</td>\n",
       "      <td>5.25</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>6.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.30</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.00</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>9.50</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.33</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5.50</td>\n",
       "      <td>13.00</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>1.33</td>\n",
       "      <td>4.50</td>\n",
       "      <td>12.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>6.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "      <td>1.17</td>\n",
       "      <td>7.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>6.50</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>1.44</td>\n",
       "      <td>4.20</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>1.14</td>\n",
       "      <td>8.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>2.38</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.20</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4</td>\n",
       "      <td>7.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.53</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.60</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2630</th>\n",
       "      <td>36</td>\n",
       "      <td>5.75</td>\n",
       "      <td>4.20</td>\n",
       "      <td>1.65</td>\n",
       "      <td>-0.472222</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2631</th>\n",
       "      <td>36</td>\n",
       "      <td>1.44</td>\n",
       "      <td>4.75</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2632</th>\n",
       "      <td>36</td>\n",
       "      <td>1.95</td>\n",
       "      <td>3.60</td>\n",
       "      <td>4.20</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2633</th>\n",
       "      <td>36</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.90</td>\n",
       "      <td>-0.416667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2634</th>\n",
       "      <td>36</td>\n",
       "      <td>1.91</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2635</th>\n",
       "      <td>36</td>\n",
       "      <td>4.50</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.91</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2636</th>\n",
       "      <td>36</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.45</td>\n",
       "      <td>-0.388889</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2637</th>\n",
       "      <td>36</td>\n",
       "      <td>1.50</td>\n",
       "      <td>4.50</td>\n",
       "      <td>7.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>36</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.60</td>\n",
       "      <td>2.90</td>\n",
       "      <td>-0.055556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2639</th>\n",
       "      <td>36</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.90</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640</th>\n",
       "      <td>37</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.20</td>\n",
       "      <td>-0.675676</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2641</th>\n",
       "      <td>37</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.60</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642</th>\n",
       "      <td>37</td>\n",
       "      <td>1.33</td>\n",
       "      <td>5.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2643</th>\n",
       "      <td>37</td>\n",
       "      <td>1.53</td>\n",
       "      <td>4.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.486486</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>37</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.40</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2645</th>\n",
       "      <td>37</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2646</th>\n",
       "      <td>37</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.00</td>\n",
       "      <td>-0.486486</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2647</th>\n",
       "      <td>37</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.40</td>\n",
       "      <td>2.10</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2648</th>\n",
       "      <td>37</td>\n",
       "      <td>1.91</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2649</th>\n",
       "      <td>37</td>\n",
       "      <td>1.55</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.75</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2650</th>\n",
       "      <td>38</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.45</td>\n",
       "      <td>-0.052632</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2651</th>\n",
       "      <td>38</td>\n",
       "      <td>1.83</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4.75</td>\n",
       "      <td>-0.526316</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2652</th>\n",
       "      <td>38</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3.80</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2653</th>\n",
       "      <td>38</td>\n",
       "      <td>1.75</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>-0.289474</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2654</th>\n",
       "      <td>38</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1.80</td>\n",
       "      <td>-0.473684</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2655</th>\n",
       "      <td>38</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.45</td>\n",
       "      <td>-0.631579</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2656</th>\n",
       "      <td>38</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.60</td>\n",
       "      <td>4.00</td>\n",
       "      <td>-0.131579</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2657</th>\n",
       "      <td>38</td>\n",
       "      <td>6.00</td>\n",
       "      <td>4.20</td>\n",
       "      <td>1.60</td>\n",
       "      <td>-1.026316</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658</th>\n",
       "      <td>38</td>\n",
       "      <td>1.95</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.33</td>\n",
       "      <td>-0.184211</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2659</th>\n",
       "      <td>38</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.90</td>\n",
       "      <td>-0.131579</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2660 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      stage  B365H  B365D  B365A  competence_difference  draw_maybe\n",
       "0         1   1.67   3.60   5.50               0.000000           0\n",
       "1         1   3.20   3.25   2.30               0.000000           1\n",
       "2         1   2.63   3.30   2.70               0.000000           1\n",
       "3         1   3.60   3.25   2.10               0.000000           1\n",
       "4         1   2.25   3.25   3.25               0.000000           1\n",
       "5         1   2.63   3.20   2.75               0.000000           1\n",
       "6         1   1.91   3.30   4.33               0.000000           1\n",
       "7         1   1.17   6.50  21.00               0.000000           0\n",
       "8         1   1.20   6.00  17.00               0.000000           0\n",
       "9         1   3.20   3.25   2.30               0.000000           1\n",
       "10        2   1.73   3.60   5.25               1.500000           0\n",
       "11        2   6.50   4.00   1.53               0.000000           0\n",
       "12        2   2.00   3.30   4.00               0.000000           1\n",
       "13        2   3.75   3.50   2.00              -1.500000           0\n",
       "14        2   9.50   5.00   1.33              -1.500000           0\n",
       "15        2   1.25   5.50  13.00              -1.500000           0\n",
       "16        3   2.60   3.25   2.80               0.000000           1\n",
       "17        3   2.30   3.20   3.25               0.000000           1\n",
       "18        3   1.33   4.50  12.00               0.000000           0\n",
       "19        3   6.50   4.00   1.53               0.000000           0\n",
       "20        3   2.10   3.25   3.75               1.000000           0\n",
       "21        3   1.17   7.00  19.00               2.000000           0\n",
       "22        3   6.50   3.80   1.57               0.000000           0\n",
       "23        3   3.40   3.30   2.20               0.000000           1\n",
       "24        3   3.10   3.25   2.38               0.000000           1\n",
       "25        3   1.44   4.20   8.00               1.000000           0\n",
       "26        4   1.14   8.00  21.00               0.750000           0\n",
       "27        4   2.38   3.25   3.20              -0.500000           1\n",
       "28        4   7.00   4.00   1.53              -0.750000           0\n",
       "29        4   2.10   3.30   3.60               0.000000           1\n",
       "...     ...    ...    ...    ...                    ...         ...\n",
       "2630     36   5.75   4.20   1.65              -0.472222           0\n",
       "2631     36   1.44   4.75   8.00               0.083333           0\n",
       "2632     36   1.95   3.60   4.20              -0.083333           0\n",
       "2633     36   2.05   3.50   3.90              -0.416667           0\n",
       "2634     36   1.91   4.00   4.00               0.666667           0\n",
       "2635     36   4.50   3.60   1.91              -0.555556           0\n",
       "2636     36   3.00   3.50   2.45              -0.388889           1\n",
       "2637     36   1.50   4.50   7.50               0.000000           0\n",
       "2638     36   2.50   3.60   2.90              -0.055556           0\n",
       "2639     36   2.05   3.60   3.90               0.361111           0\n",
       "2640     37   3.40   3.20   2.20              -0.675676           0\n",
       "2641     37   2.05   3.40   3.60               0.243243           0\n",
       "2642     37   1.33   5.00   9.00               0.540541           0\n",
       "2643     37   1.53   4.00   6.00               0.486486           0\n",
       "2644     37   3.75   3.40   2.00               0.054054           0\n",
       "2645     37   3.40   3.30   2.15               0.054054           0\n",
       "2646     37   3.60   3.50   2.00              -0.486486           0\n",
       "2647     37   3.40   3.40   2.10              -1.000000           0\n",
       "2648     37   1.91   3.50   4.00               0.270270           0\n",
       "2649     37   1.55   4.00   5.75               0.027027           0\n",
       "2650     38   3.00   3.50   2.45              -0.052632           0\n",
       "2651     38   1.83   3.75   4.75              -0.526316           0\n",
       "2652     38   2.00   3.80   3.80               0.184211           0\n",
       "2653     38   1.75   4.00   5.00              -0.289474           0\n",
       "2654     38   5.00   3.70   1.80              -0.473684           0\n",
       "2655     38   3.20   3.25   2.45              -0.631579           0\n",
       "2656     38   2.00   3.60   4.00              -0.131579           0\n",
       "2657     38   6.00   4.20   1.60              -1.026316           0\n",
       "2658     38   1.95   3.50   4.33              -0.184211           0\n",
       "2659     38   2.70   3.20   2.90              -0.131579           0\n",
       "\n",
       "[2660 rows x 6 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
